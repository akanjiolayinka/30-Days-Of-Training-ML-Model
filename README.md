# 30 Days Of Datasets

A 30-day data analysis challenge focused on exploring real-world datasets, uncovering insights, and strengthening AI/ML foundations using Python.

## Project Structure

Each day folder contains:
- **data/** - Raw and processed datasets
- **models/** - Machine learning models and saved files
- **notebooks/** - Jupyter notebooks with analysis
- **viz/** - Visualizations and charts
- **README.md** - Day-specific documentation

## Days Overview

- Day 1: Netflix Data Analysis
- Day 2: Earthquake & Tsunami Data
- Day 5: Healthcare Staff & Patients Management
- Day 6: Earthquake & Tsunami Analysis
- Day 7: Fruit Classification
- Day 9: Unified Dataset Analysis
- Day 10: Insurance Data
- Day 13: GPU Performance (1986-2026)
- Day 16: Energy Consumption
- Day 19: Students Performance
- Day 22: Housing Price Prediction
- Day 23: Unified Dataset
- Day 25: Iris Classification
- Day 26: Goodreads Books Dataset
- Day 28: Meal Metadata & Food Data
- Day 29: Car Price Prediction
- Day 30: Housing Price Data

## Getting Started

1. Navigate to any day folder
2. Check the README.md for that day's objectives
3. Explore the notebooks in the `notebooks/` directory
4. Data files are located in the `data/` folder

## Technologies Used

- Python
- Pandas
- NumPy
- Scikit-learn
- Matplotlib/Seaborn
- Jupyter Notebooks

## Contributing

This is a personal learning project, but feel free to fork and create your own 30-day challenge!
