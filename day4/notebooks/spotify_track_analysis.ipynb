{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 4: Spotify Track Data Analysis\n",
    "\n",
    "Exploratory Data Analysis and Classification Modeling on Spotify Track Datasets.\n",
    "\n",
    "We analyze track popularity, artist metrics, and other features to understand patterns in music data, then build classification models to predict popularity categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Visualization\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.subplots as sp\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix,\n",
    "    accuracy_score, precision_score, recall_score, f1_score\n",
    ")\n",
    "\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Ensure output directories exist\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "os.makedirs('../viz', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load both datasets\n",
    "track_data = pd.read_csv('../data/track_data_final.csv')\n",
    "spotify_clean = pd.read_csv('../data/spotify_data_clean.csv')\n",
    "\n",
    "print('=== track_data_final.csv ===')\n",
    "print(f'Shape: {track_data.shape}')\n",
    "display(track_data.head())\n",
    "\n",
    "print('\\n=== spotify_data_clean.csv ===')\n",
    "print(f'Shape: {spotify_clean.shape}')\n",
    "display(spotify_clean.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=== track_data_final info ===')\n",
    "display(track_data.info())\n",
    "print('\\n=== spotify_data_clean info ===')\n",
    "display(spotify_clean.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=== track_data_final - Statistical Summary ===')\n",
    "display(track_data.describe())\n",
    "print('\\n=== Missing Values ===')\n",
    "display(track_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=== spotify_data_clean - Statistical Summary ===')\n",
    "display(spotify_clean.describe())\n",
    "print('\\n=== Missing Values ===')\n",
    "display(spotify_clean.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "We'll work primarily with `track_data_final.csv` for modeling since it has duration in milliseconds. We'll also use `spotify_data_clean.csv` for supplementary analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing artist_popularity or artist_followers\n",
    "df = track_data.dropna(subset=['artist_popularity', 'artist_followers']).copy()\n",
    "\n",
    "# Convert explicit to int\n",
    "df['explicit'] = df['explicit'].astype(int)\n",
    "\n",
    "# Parse release date to extract year\n",
    "df['release_year'] = pd.to_datetime(df['album_release_date'], errors='coerce').dt.year\n",
    "\n",
    "# Convert duration from ms to minutes for readability\n",
    "df['track_duration_min'] = df['track_duration_ms'] / 60000\n",
    "\n",
    "# Create popularity category for classification\n",
    "df['popularity_category'] = pd.cut(\n",
    "    df['track_popularity'],\n",
    "    bins=[-1, 25, 50, 75, 100],\n",
    "    labels=['Low', 'Medium', 'High', 'Very High']\n",
    ")\n",
    "\n",
    "print(f'Cleaned dataset shape: {df.shape}')\n",
    "display(df['popularity_category'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "### Track Popularity Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram of track popularity\n",
    "axes[0].hist(df['track_popularity'], bins=40, color='#1DB954', edgecolor='black', alpha=0.8)\n",
    "axes[0].set_title('Distribution of Track Popularity')\n",
    "axes[0].set_xlabel('Track Popularity')\n",
    "axes[0].set_ylabel('Count')\n",
    "\n",
    "# Popularity category counts\n",
    "cat_counts = df['popularity_category'].value_counts().sort_index()\n",
    "axes[1].bar(cat_counts.index.astype(str), cat_counts.values, color=['#e74c3c','#f39c12','#2ecc71','#3498db'], edgecolor='black')\n",
    "axes[1].set_title('Tracks by Popularity Category')\n",
    "axes[1].set_xlabel('Category')\n",
    "axes[1].set_ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../viz/popularity_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Saved: viz/popularity_distribution.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artist Popularity vs Track Popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Scatter: artist popularity vs track popularity\n",
    "axes[0].scatter(df['artist_popularity'], df['track_popularity'], alpha=0.3, s=10, color='#1DB954')\n",
    "axes[0].set_title('Artist Popularity vs Track Popularity')\n",
    "axes[0].set_xlabel('Artist Popularity')\n",
    "axes[0].set_ylabel('Track Popularity')\n",
    "\n",
    "# Scatter: artist followers vs track popularity\n",
    "axes[1].scatter(df['artist_followers'], df['track_popularity'], alpha=0.3, s=10, color='#e74c3c')\n",
    "axes[1].set_title('Artist Followers vs Track Popularity')\n",
    "axes[1].set_xlabel('Artist Followers')\n",
    "axes[1].set_ylabel('Track Popularity')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../viz/artist_vs_track_popularity.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Saved: viz/artist_vs_track_popularity.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = ['track_popularity', 'track_duration_ms', 'artist_popularity',\n",
    "                'artist_followers', 'track_number', 'album_total_tracks', 'explicit']\n",
    "corr = df[numeric_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr, annot=True, fmt='.2f', cmap='RdYlGn', center=0,\n",
    "            square=True, linewidths=0.5)\n",
    "plt.title('Correlation Heatmap of Numeric Features')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../viz/correlation_heatmap.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Saved: viz/correlation_heatmap.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 15 Artists by Average Track Popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_artists = (\n",
    "    df.groupby('artist_name')['track_popularity']\n",
    "    .agg(['mean', 'count'])\n",
    "    .query('count >= 3')\n",
    "    .sort_values('mean', ascending=False)\n",
    "    .head(15)\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(top_artists.index[::-1], top_artists['mean'].values[::-1], color='#1DB954', edgecolor='black')\n",
    "plt.xlabel('Average Track Popularity')\n",
    "plt.title('Top 15 Artists by Average Track Popularity (min 3 tracks)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../viz/top_artists.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Saved: viz/top_artists.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box Plot: Track Popularity by Album Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "album_types = df['album_type'].value_counts().index[:5]  # top album types\n",
    "subset = df[df['album_type'].isin(album_types)]\n",
    "sns.boxplot(data=subset, x='album_type', y='track_popularity', palette='Set2')\n",
    "plt.title('Track Popularity by Album Type')\n",
    "plt.xlabel('Album Type')\n",
    "plt.ylabel('Track Popularity')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../viz/popularity_by_album_type.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Saved: viz/popularity_by_album_type.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explicit vs Non-Explicit Track Popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "sns.boxplot(data=df, x='explicit', y='track_popularity', palette=['#2ecc71', '#e74c3c'])\n",
    "plt.xticks([0, 1], ['Non-Explicit', 'Explicit'])\n",
    "plt.title('Track Popularity: Explicit vs Non-Explicit')\n",
    "plt.xlabel('Explicit')\n",
    "plt.ylabel('Track Popularity')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../viz/explicit_vs_popularity.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Saved: viz/explicit_vs_popularity.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genre Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse genres (stored as string representations of lists)\n",
    "import ast\n",
    "\n",
    "def parse_genres(genre_str):\n",
    "    \"\"\"Parse genre string to list.\"\"\"\n",
    "    if pd.isna(genre_str) or genre_str in ('N/A', '[]', ''):\n",
    "        return []\n",
    "    try:\n",
    "        return ast.literal_eval(genre_str)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return [genre_str.strip()]\n",
    "\n",
    "all_genres = df['artist_genres'].apply(parse_genres).explode()\n",
    "genre_counts = all_genres.value_counts().head(20)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(genre_counts.index[::-1], genre_counts.values[::-1], color='#3498db', edgecolor='black')\n",
    "plt.xlabel('Number of Tracks')\n",
    "plt.title('Top 20 Genres by Track Count')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../viz/top_genres.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Saved: viz/top_genres.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Observations\n",
    "\n",
    "- **Popularity Distribution**: Track popularity is right-skewed with many tracks having low popularity scores. Most tracks fall in the Low-Medium range.\n",
    "- **Artist-Track Correlation**: Artist popularity has a moderate positive correlation with track popularity; more popular artists tend to have more popular tracks.\n",
    "- **Artist Followers**: High follower count shows some correlation with track popularity, but the relationship is noisy.\n",
    "- **Album Type**: Tracks from albums tend to have wider popularity ranges than singles or compilations.\n",
    "- **Explicit Content**: Explicit and non-explicit tracks show similar popularity distributions.\n",
    "- **Genre Trends**: Pop, hip-hop, and related genres dominate the track count."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Models\n",
    "\n",
    "We predict popularity category (Low / Medium / High / Very High) using numeric features.\n",
    "\n",
    "### Feature Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features for modeling\n",
    "feature_cols = ['track_duration_ms', 'artist_popularity', 'artist_followers',\n",
    "                'track_number', 'album_total_tracks', 'explicit']\n",
    "\n",
    "model_df = df[feature_cols + ['popularity_category']].dropna()\n",
    "\n",
    "# Encode target\n",
    "le = LabelEncoder()\n",
    "model_df['target'] = le.fit_transform(model_df['popularity_category'])\n",
    "\n",
    "X = model_df[feature_cols]\n",
    "y = model_df['target']\n",
    "\n",
    "print(f'Features shape: {X.shape}')\n",
    "print(f'Target distribution:\\n{model_df[\"popularity_category\"].value_counts().sort_index()}')\n",
    "print(f'\\nTarget encoding: {dict(zip(le.classes_, le.transform(le.classes_)))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split & Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f'Train: {X_train.shape[0]} samples')\n",
    "print(f'Test:  {X_test.shape[0]} samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LogisticRegression(max_iter=1000, random_state=42, multi_class='multinomial')\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "lr_pred = lr_model.predict(X_test_scaled)\n",
    "\n",
    "print('=== Logistic Regression ===')\n",
    "print(f'Accuracy: {accuracy_score(y_test, lr_pred):.4f}')\n",
    "print(f'\\nClassification Report:')\n",
    "print(classification_report(y_test, lr_pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "\n",
    "print('=== Random Forest Classifier ===')\n",
    "print(f'Accuracy: {accuracy_score(y_test, rf_pred):.4f}')\n",
    "print(f'\\nClassification Report:')\n",
    "print(classification_report(y_test, rf_pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build comparison table\n",
    "scoreboard = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'Random Forest'],\n",
    "    'Accuracy': [\n",
    "        accuracy_score(y_test, lr_pred),\n",
    "        accuracy_score(y_test, rf_pred)\n",
    "    ],\n",
    "    'Precision (weighted)': [\n",
    "        precision_score(y_test, lr_pred, average='weighted'),\n",
    "        precision_score(y_test, rf_pred, average='weighted')\n",
    "    ],\n",
    "    'Recall (weighted)': [\n",
    "        recall_score(y_test, lr_pred, average='weighted'),\n",
    "        recall_score(y_test, rf_pred, average='weighted')\n",
    "    ],\n",
    "    'F1 Score (weighted)': [\n",
    "        f1_score(y_test, lr_pred, average='weighted'),\n",
    "        f1_score(y_test, rf_pred, average='weighted')\n",
    "    ]\n",
    "})\n",
    "\n",
    "display(scoreboard)\n",
    "\n",
    "# Bar chart comparison\n",
    "metrics = ['Accuracy', 'Precision (weighted)', 'Recall (weighted)', 'F1 Score (weighted)']\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "bars1 = ax.bar(x - width/2, scoreboard[metrics].iloc[0].values, width, label='Logistic Regression', color='#3498db')\n",
    "bars2 = ax.bar(x + width/2, scoreboard[metrics].iloc[1].values, width, label='Random Forest', color='#1DB954')\n",
    "\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Model Comparison')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(metrics, rotation=15)\n",
    "ax.legend()\n",
    "ax.set_ylim(0, 1)\n",
    "ax.bar_label(bars1, fmt='%.3f', fontsize=8)\n",
    "ax.bar_label(bars2, fmt='%.3f', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../viz/model_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Saved: viz/model_comparison.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "for ax, pred, name in [(axes[0], lr_pred, 'Logistic Regression'),\n",
    "                        (axes[1], rf_pred, 'Random Forest')]:\n",
    "    cm = confusion_matrix(y_test, pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n",
    "                xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "    ax.set_title(f'Confusion Matrix: {name}')\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_ylabel('Actual')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../viz/confusion_matrices.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Saved: viz/confusion_matrices.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = pd.Series(rf_model.feature_importances_, index=feature_cols).sort_values()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "importances.plot(kind='barh', color='#1DB954', edgecolor='black')\n",
    "plt.title('Feature Importance (Random Forest)')\n",
    "plt.xlabel('Importance')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../viz/feature_importance.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Saved: viz/feature_importance.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save both models\n",
    "joblib.dump(lr_model, '../models/spotify_lr_model.joblib')\n",
    "joblib.dump(rf_model, '../models/spotify_rf_model.joblib')\n",
    "\n",
    "# Also save the scaler and label encoder for reuse\n",
    "joblib.dump(scaler, '../models/spotify_scaler.joblib')\n",
    "joblib.dump(le, '../models/spotify_label_encoder.joblib')\n",
    "\n",
    "print('Models saved to ../models/')\n",
    "print('  - spotify_lr_model.joblib')\n",
    "print('  - spotify_rf_model.joblib')\n",
    "print('  - spotify_scaler.joblib')\n",
    "print('  - spotify_label_encoder.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| Metric | Logistic Regression | Random Forest |\n",
    "|--------|-------------------|---------------|\n",
    "| Accuracy | see output above | see output above |\n",
    "| Precision | see output above | see output above |\n",
    "| Recall | see output above | see output above |\n",
    "| F1 Score | see output above | see output above |\n",
    "\n",
    "Both models were trained to classify Spotify tracks into popularity categories (Low, Medium, High, Very High). Artist popularity and artist followers are the most predictive features for track popularity classification."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}